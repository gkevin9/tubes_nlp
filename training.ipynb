{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPerWord(file):\n",
    "    words = []\n",
    "    f = open(file, 'r') #open file\n",
    "    for line in f:\n",
    "        words = line.split(' ') #tiap satu baris split per kata\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    words[len(words)-1] = words[len(words)-1].replace('\\n',' ')\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extFeature(words):\n",
    "    listOfDictFeature = []\n",
    "    i = 0\n",
    "    flag = 0 #0 = not tag, 1 = person, 2 = location, 3 = organization\n",
    "    for i in range(len(words)): #iterasi dari awal tiap kata\n",
    "        dictFeature = {}\n",
    "        #cek apakah word tersebut tag\n",
    "        if flag == 0: \n",
    "            if words[i] == '<person>':\n",
    "                flag = 1\n",
    "                continue\n",
    "            if words[i] == '<location>':\n",
    "                flag = 2\n",
    "                continue\n",
    "            if words[i] == '<organization>':\n",
    "                flag = 3\n",
    "                continue\n",
    "            else:\n",
    "                dictFeature = inputToDict(flag, words, i)\n",
    "        elif flag == 1:\n",
    "            if words[i] == '</person>':\n",
    "                flag = 0\n",
    "                continue\n",
    "            dictFeature = inputToDict(flag, words, i)\n",
    "        elif flag == 2:\n",
    "            if words[i] == '</location>':\n",
    "                flag = 0\n",
    "                continue\n",
    "            dictFeature = inputToDict(flag, words, i)\n",
    "        elif flag == 3:\n",
    "            if words[i] == '</organization>':\n",
    "                flag = 0\n",
    "                continue\n",
    "            dictFeature = inputToDict(flag, words, i)\n",
    "        \n",
    "        listOfDictFeature.append(dictFeature)\n",
    "        \n",
    "    return listOfDictFeature\n",
    "\n",
    "def inputToDict(flag, words, i):\n",
    "    dictFeature = {}\n",
    "    \n",
    "    dictFeature['index'] = i    \n",
    "    dictFeature['first_upper_case'] = isFirstUpper(words[i])\n",
    "    dictFeature['prev_word'] = isEdge(i, words)\n",
    "    dictFeature['word'] = words[i]\n",
    "    \n",
    "    if flag == 1:\n",
    "        dictFeature['jenis'] = 'person'\n",
    "    elif flag == 2:\n",
    "        dictFeature['jenis'] = 'location'\n",
    "    elif flag == 3:\n",
    "        dictFeature['jenis'] = 'organization'\n",
    "    else:\n",
    "        dictFeature['jenis'] = 'o'\n",
    "    \n",
    "    return dictFeature\n",
    "\n",
    "def isFirstUpper(word):\n",
    "    if word[0].isupper():\n",
    "        return 'y'\n",
    "    else:\n",
    "        return 'n'\n",
    "    \n",
    "def isEdge(i, words):\n",
    "    if i == 0:\n",
    "        return 'null'\n",
    "    elif isTag(words[i-1]):\n",
    "        return words[i-2]\n",
    "    else:\n",
    "        return words[i-1]\n",
    "\n",
    "def isTag(word):\n",
    "    tagWord = ['<person>','</person>','<location>','</location>','<organization>','</organization>']\n",
    "    if word in tagWord:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'first_upper_case': 'y', 'prev_word': 'null', 'word': 'Menteri', 'jenis': 'o'}\n",
      "{'index': 1, 'first_upper_case': 'y', 'prev_word': 'Menteri', 'word': 'Pertahanan', 'jenis': 'o'}\n",
      "{'index': 3, 'first_upper_case': 'y', 'prev_word': 'Pertahanan', 'word': 'Prabowo', 'jenis': 'person'}\n",
      "{'index': 4, 'first_upper_case': 'y', 'prev_word': 'Prabowo', 'word': 'Subianto', 'jenis': 'person'}\n",
      "{'index': 6, 'first_upper_case': 'n', 'prev_word': 'Subianto', 'word': 'dikabarkan', 'jenis': 'o'}\n",
      "{'index': 7, 'first_upper_case': 'n', 'prev_word': 'dikabarkan', 'word': 'akan', 'jenis': 'o'}\n",
      "{'index': 8, 'first_upper_case': 'n', 'prev_word': 'akan', 'word': 'ke', 'jenis': 'o'}\n",
      "{'index': 10, 'first_upper_case': 'y', 'prev_word': 'ke', 'word': 'Amerika', 'jenis': 'location'}\n",
      "{'index': 11, 'first_upper_case': 'y', 'prev_word': 'Amerika', 'word': 'Serikat', 'jenis': 'location'}\n",
      "{'index': 12, 'first_upper_case': 'n', 'prev_word': 'Serikat', 'word': '(AS)', 'jenis': 'location'}\n",
      "{'index': 14, 'first_upper_case': 'n', 'prev_word': '(AS)', 'word': '.', 'jenis': 'o'}\n",
      "{'index': 15, 'first_upper_case': 'y', 'prev_word': '.', 'word': 'Padahal', 'jenis': 'o'}\n",
      "{'index': 16, 'first_upper_case': 'n', 'prev_word': 'Padahal', 'word': 'sebelumnya', 'jenis': 'o'}\n",
      "{'index': 18, 'first_upper_case': 'y', 'prev_word': 'sebelumnya', 'word': 'Prabowo', 'jenis': 'person'}\n",
      "{'index': 20, 'first_upper_case': 'n', 'prev_word': 'Prabowo', 'word': 'sempat', 'jenis': 'o'}\n",
      "{'index': 21, 'first_upper_case': 'n', 'prev_word': 'sempat', 'word': 'ditolak', 'jenis': 'o'}\n",
      "{'index': 22, 'first_upper_case': 'n', 'prev_word': 'ditolak', 'word': 'masuk', 'jenis': 'o'}\n",
      "{'index': 23, 'first_upper_case': 'n', 'prev_word': 'masuk', 'word': 'ke', 'jenis': 'o'}\n",
      "{'index': 24, 'first_upper_case': 'n', 'prev_word': 'ke', 'word': 'negara', 'jenis': 'o'}\n",
      "{'index': 25, 'first_upper_case': 'y', 'prev_word': 'negara', 'word': 'Paman', 'jenis': 'o'}\n",
      "{'index': 26, 'first_upper_case': 'y', 'prev_word': 'Paman', 'word': 'Sam', 'jenis': 'o'}\n",
      "{'index': 27, 'first_upper_case': 'n', 'prev_word': 'Sam', 'word': 'itu.', 'jenis': 'o'}\n",
      "{'index': 28, 'first_upper_case': 'n', 'prev_word': 'itu.', 'word': '\"Intinya', 'jenis': 'o'}\n",
      "{'index': 29, 'first_upper_case': 'n', 'prev_word': '\"Intinya', 'word': 'jabatan', 'jenis': 'o'}\n",
      "{'index': 30, 'first_upper_case': 'n', 'prev_word': 'jabatan', 'word': 'resmi', 'jenis': 'o'}\n",
      "{'index': 31, 'first_upper_case': 'n', 'prev_word': 'resmi', 'word': 'bukan', 'jenis': 'o'}\n",
      "{'index': 32, 'first_upper_case': 'n', 'prev_word': 'bukan', 'word': 'jaminan', 'jenis': 'o'}\n",
      "{'index': 33, 'first_upper_case': 'n', 'prev_word': 'jaminan', 'word': 'bisa', 'jenis': 'o'}\n",
      "{'index': 34, 'first_upper_case': 'n', 'prev_word': 'bisa', 'word': 'masuk', 'jenis': 'o'}\n",
      "{'index': 35, 'first_upper_case': 'n', 'prev_word': 'masuk', 'word': 'ke', 'jenis': 'o'}\n",
      "{'index': 37, 'first_upper_case': 'y', 'prev_word': 'ke', 'word': 'AS', 'jenis': 'location'}\n",
      "{'index': 39, 'first_upper_case': 'n', 'prev_word': 'AS', 'word': ',\"', 'jenis': 'o'}\n",
      "{'index': 40, 'first_upper_case': 'n', 'prev_word': ',\"', 'word': 'kata', 'jenis': 'o'}\n",
      "{'index': 41, 'first_upper_case': 'n', 'prev_word': 'kata', 'word': 'guru', 'jenis': 'o'}\n",
      "{'index': 42, 'first_upper_case': 'n', 'prev_word': 'guru', 'word': 'besar', 'jenis': 'o'}\n",
      "{'index': 43, 'first_upper_case': 'n', 'prev_word': 'besar', 'word': 'hukum', 'jenis': 'o'}\n",
      "{'index': 44, 'first_upper_case': 'n', 'prev_word': 'hukum', 'word': 'internasional', 'jenis': 'o'}\n",
      "{'index': 46, 'first_upper_case': 'y', 'prev_word': 'internasional', 'word': 'Universitas', 'jenis': 'organization'}\n",
      "{'index': 47, 'first_upper_case': 'y', 'prev_word': 'Universitas', 'word': 'Indonesia', 'jenis': 'organization'}\n",
      "{'index': 48, 'first_upper_case': 'n', 'prev_word': 'Indonesia', 'word': '(UI)', 'jenis': 'organization'}\n",
      "{'index': 51, 'first_upper_case': 'y', 'prev_word': '</organization>', 'word': 'Prof', 'jenis': 'person'}\n",
      "{'index': 52, 'first_upper_case': 'y', 'prev_word': 'Prof', 'word': 'Hikmahanto', 'jenis': 'person'}\n",
      "{'index': 53, 'first_upper_case': 'y', 'prev_word': 'Hikmahanto', 'word': 'Juwana', 'jenis': 'person'}\n",
      "{'index': 55, 'first_upper_case': 'n', 'prev_word': 'Juwana', 'word': 'kepada', 'jenis': 'o'}\n",
      "{'index': 56, 'first_upper_case': 'n', 'prev_word': 'kepada', 'word': 'detikcom,', 'jenis': 'o'}\n",
      "{'index': 57, 'first_upper_case': 'y', 'prev_word': 'detikcom,', 'word': 'Rabu', 'jenis': 'o'}\n",
      "{'index': 58, 'first_upper_case': 'n', 'prev_word': 'Rabu', 'word': '(30/10/2019). ', 'jenis': 'o'}\n"
     ]
    }
   ],
   "source": [
    "words = readPerWord('berita1.txt')\n",
    "listOfDictFeature = extFeature(words)\n",
    "for i in listOfDictFeature:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"training.pickle\",\"wb\")\n",
    "pickle.dump(listOfDictFeature, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
